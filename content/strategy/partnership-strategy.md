# Impact-Edu.ai Partnership Strategy

*Last updated: 2026-02-26*

## Positioning

**Impact-Edu builds the open applied layer on top of open education infrastructure.**

CZI built the Learning Commons Knowledge Graph (250K standards, 2K learning components, 273K relationships). Student Achievement Partners built the Coherence Map. We build the tools that make these frameworks actionable — AI-generated assessment items, LLM evaluators, adaptive practice, calibrated item banks — all open source, CC-licensed, free.

Most players in AI & education fall into one of three camps:
- **Proprietary platforms** (Khan Academy, Duolingo, Savvas) — great products, walled gardens
- **Pure research** (universities, AIED community) — papers, not products
- **Infrastructure builders** (CZI, Digital Promise) — foundations, not applications

We are the fourth camp: **applied open tools built on open infrastructure.** We don't compete with the knowledge graph — we're the first serious project built on top of it.

## Audience Priority

1. **Foundations** — fund the work (Gates, Schmidt, CZI, NSF)
2. **Researchers** — use the work, validate it, cite it, build credibility
3. **Other builders** — build on Open Items via API, extend the ecosystem
4. **Schools** — benefit through the tools others build, not direct adoption (yet)

Each audience creates credibility for the next.

### Why researchers before schools

Schools are slow (12-18 month procurement cycles, IT approval, PD requirements). Researchers are fast — an AIED researcher who needs calibrated items for a study can use Open Items next week. They cite us in papers. Those papers build credibility with foundations. Researchers sit on advisory panels, review CZI's work, advise policy. They're force multipliers.

### Why builders before schools

We don't need to reach every student directly. If 50 ed-tech startups are pulling from our calibrated item bank via API, the impact scales without us running a student-facing product at scale. We become the npm of educational assessment — the default open dataset everyone starts from.

## Partnership Tiers

### Tier 1: Approach Now — Natural Alignment, Low Friction

**CZI / Learning Commons**
- We're already building on their knowledge graph
- Strategy: Show, don't ask. Ship Open Items, write up the integration, share with their team
- They may want to feature us as a case study — costs them nothing, gives us everything
- Key asset: We're the first applied project demonstrating real use of their graph
- Status: They know us, relationship is real but undefined. Need to make the integration visible.

**Student Achievement Partners / Coherence Map**
- Their coherence map powers the prerequisite traversal in our system
- Strategy: Same as CZI — "We built adaptive learning progressions on top of your coherence map. Here's the demo."
- Small org that would love to see their work used this way
- Low-effort, high-signal partnership

### Tier 2: After Open Items Launch — Needs the Demo

**Illustrative Math / Open Up Resources**
- They have great curriculum but no assessment platform
- Open Items as "the free assessment layer for open curricula"
- Requires items mapped to their scope & sequence (specific integration work)

**NWEA Research**
- Publishes openly on measurement science
- Our LLM evaluator work (AIED 2026: 200 conditions, 15+ models) is directly relevant
- The paper opens the door, Open Items gives them something to collaborate on

**OpenSciEd / CPALMS**
- Open curriculum organizations that need assessment infrastructure
- Same play as Illustrative Math — we're the assessment layer

### Tier 3: Needs Momentum from Tier 1-2

**Digital Promise**
- Learning engineering, micro-credentials, AI guidance for districts
- Bigger, slower org. Responds to momentum, not cold pitches.

**ISTE**
- AI in education standards, teacher PD frameworks
- Having CZI and SAP visibly engaged makes this conversation 10x easier

**Gates Foundation / Schmidt Futures**
- Major funders. Need to see ecosystem traction.
- Pitch: "We're building the open rails that make every AI tutoring tool better"
- Not "we have a nice item bank" — that's too small

## First Move

1. Get Open Items live at `openitems.impact-edu.ai` (curated public features only)
2. Write a technical post: "Building an Open Assessment Pipeline on the Learning Commons Knowledge Graph"
3. Share directly with CZI and SAP contacts
4. Not asking for anything — giving them something to react to

## Key Assets

- **Open Items platform** — 34K+ CC-licensed assessment items, AI generation pipeline, LLM evaluators, adaptive practice
- **CZI Knowledge Graph integration** — working implementation, not just a concept
- **AIED 2026 paper** — 200 experimental conditions, 15+ models, LLM difficulty estimation
- **Track record** — SmartPaper (5M+ assessments), PlayPower (10M+ students), UpGrade (open-source A/B testing), 75+ publications
- **Nonprofit structure** — Wisdom Frontiers 501(c)(3), independent governance, published conflict of interest policy

## What We're NOT

- Not a commercial ed-tech company (that's Play Power Labs, separate entity)
- Not competing with CZI or Learning Commons — building on top of them
- Not trying to replace district assessment systems — providing the open data layer underneath
- Not promising to solve everything — focused on open assessment infrastructure specifically
